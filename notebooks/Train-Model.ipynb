{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5e6868d-ea27-4869-b843-47608f964a87",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "208bce97-5ebb-4a2c-9f66-4f44d7953d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from src.model import VisionModel\n",
    "from src.noises import add_noise\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a2228f-cba0-4bad-aa03-3e29db0829b0",
   "metadata": {},
   "source": [
    "# 1. Transform function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8f3f9df1-3a74-4077-a953-8b702d123116",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddNoise(torch.nn.Module):\n",
    "    def forward(self, img):\n",
    "        img = np.array(img)\n",
    "        noisy_image = add_noise(img, noise_type='exponential', scale=100,sigma=150)\n",
    "        noisy_image = add_noise(noisy_image, noise_type='gaussian', scale=100,sigma=150)\n",
    "\n",
    "        return Image.fromarray(noisy_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5d7abb28-5793-4a07-9c53-342fe44331fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize((28, 28)),       # Resize the image to 256x256 pixels\n",
    "    transforms.ToTensor(),            # Convert the image to a PyTorch tensor\n",
    "    #transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize the image\n",
    "    transforms.Normalize(mean=[0.485], std=[0.229])  # Normalize the image\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52548b39-b44d-4426-81c8-601ad5c42861",
   "metadata": {},
   "source": [
    "# 2. Load Train and Test Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173d6527-8f51-45d8-b4d7-ba8f4580a3ce",
   "metadata": {},
   "source": [
    "## 2.1 MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7bd9b740-65b9-4ff6-bfb0-883d4073b42e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTCustomDataset(MNIST):\n",
    "    def __init__(self,root_dir,train,transform_function,noise_function):\n",
    "        super().__init__(root_dir,download=True,train=train)\n",
    "        self.transform_function = transform_function\n",
    "        self.noise_function = noise_function\n",
    "    def __getitem__(self, index: int):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        img, target = self.data[index], int(self.targets[index])\n",
    "\n",
    "        # doing this so that it is consistent with all other datasets\n",
    "        # to return a PIL Image\n",
    "        original_img = Image.fromarray(img.numpy(), mode=\"L\")\n",
    "        noise_img = original_img.copy()\n",
    "\n",
    "        original_img = self.transform_function(original_img)\n",
    "        \n",
    "        noise_img = self.noise_function(noise_img)\n",
    "        noise_img = self.transform_function(noise_img)\n",
    "\n",
    "        return original_img, noise_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a6e1595d-c8b8-4234-ba53-fde1abc395b1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mnist_dataset_train = MNISTCustomDataset(\"./\",True,transform,AddNoise())\n",
    "mnist_dataset_test = MNISTCustomDataset(\"./\",False,transform,AddNoise())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "fccde3eb-4338-4891-8267-1ace34440e08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.86\n",
      "Test: 0.14\n"
     ]
    }
   ],
   "source": [
    "total = mnist_dataset_train.__len__() + mnist_dataset_test.__len__()\n",
    "\n",
    "print(f\"Train: {round(mnist_dataset_train.__len__()/total,2)}\\nTest: {round(mnist_dataset_test.__len__()/total,2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3665c8-bff2-4260-b650-dca176c83da1",
   "metadata": {},
   "source": [
    "## 2.2 MNIST Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f725876b-ccb8-446f-a71f-4bed7a864007",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "num_workers = 1\n",
    "\n",
    "mnist_dataloader_train = DataLoader(\n",
    "    mnist_dataset_train,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    shuffle=True)\n",
    "\n",
    "mnist_dataloader_test = DataLoader(\n",
    "    mnist_dataset_test,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9935c73d-92e7-4574-aacd-de610ce65c3c",
   "metadata": {},
   "source": [
    "# 3. Vision Transform Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b740fdd4-be9a-4281-89af-3a222ec36316",
   "metadata": {},
   "source": [
    "## 3.1 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "fbcd7d50-25ad-4313-a6f9-deab9367c992",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = VisionModel(\n",
    "    img_size=(batch_size,1,28,28),\n",
    "    patch_size=4,\n",
    "    token_len=512)\n",
    "\n",
    "model = model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b80bdaa-7293-4d63-9961-8d0675a4b94a",
   "metadata": {},
   "source": [
    "## 3.2 Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "2ab064cb-0c42-4fa1-a687-fb60051cb159",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7d4bfa-0374-4986-b5ea-d3e0d0cdaeb3",
   "metadata": {},
   "source": [
    "## 3.3 Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "3cf2272c-a52d-4fa9-9a76-d15eb8951fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.001\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e1b9673-59da-4184-abe1-64bc83d4bcf3",
   "metadata": {},
   "source": [
    "# 3. Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "12bb94b3-70d6-4e4d-b17f-7a8303140406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "569ff7c1e93a4fe69b14d33bbbacde0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e368731ee8544e78f65237303fe6897",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3750 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[121], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m total_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ori_img, noi_img \u001b[38;5;129;01min\u001b[39;00m (pbar \u001b[38;5;241m:=\u001b[39m tqdm(mnist_dataloader_train)):\n\u001b[0;32m----> 8\u001b[0m     noi_img \u001b[38;5;241m=\u001b[39m noi_img\u001b[38;5;241m.\u001b[39mcuda()\n\u001b[1;32m      9\u001b[0m     denoised_img \u001b[38;5;241m=\u001b[39m model(noi_img)\n\u001b[1;32m     10\u001b[0m     denoised_img \u001b[38;5;241m=\u001b[39m denoised_img\u001b[38;5;241m.\u001b[39mcpu()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 64\n",
    "\n",
    "model = model.train()\n",
    "\n",
    "for epoch in tqdm(range(1,epochs+1)):\n",
    "    total_loss = 0\n",
    "    for ori_img, noi_img in (pbar := tqdm(mnist_dataloader_train)):\n",
    "        noi_img = noi_img.cuda()\n",
    "        denoised_img = model(noi_img)\n",
    "        denoised_img = denoised_img.cpu()\n",
    "        \n",
    "        loss = loss_fn(denoised_img, ori_img)\n",
    "\n",
    "        optimizer.zero_grad()    \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()/batch_size\n",
    "        pbar.set_description(f\"Loss: {total_loss}\")\n",
    "    print(total_loss)\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
